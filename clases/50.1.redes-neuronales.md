# Redes Neuronales para Principiantes

## üß† Fundamentos de una red neuronal

### üéØ Objetivo general

Comprender c√≥mo una red neuronal aprende y toma decisiones, partiendo del perceptr√≥n y extendiendo hacia redes con aprendizaje mediante gradiente descendente.

---

### **Sesi√≥n 1 ‚Äì El perceptr√≥n: la neurona m√°s simple**

**Objetivos:**
- Comprender el modelo de una neurona artificial.
- Implementar un perceptr√≥n para una compuerta l√≥gica AND.
- Resolver anal√≠ticamente los pesos y el sesgo.
- Visualizar la frontera de decisi√≥n.
    
**Contenido:**
1.  Motivaci√≥n: ¬øqu√© es ‚Äúaprender‚Äù para una m√°quina?
2.  Estructura de una neurona: entradas, pesos, sesgo, funci√≥n de activaci√≥n (escal√≥n).
3.  Ejemplo de compuerta AND:
    - Ecuaci√≥n:  
        $y = f(w_1x_1 + w_2x_2 + b)$
    - Resolver anal√≠ticamente los pesos que satisfacen AND.
    - Mostrar c√≥mo el perceptr√≥n solo puede resolver problemas linealmente separables.

**Pr√°ctica (Python puro):**
- Escribir c√≥digo del perceptr√≥n con funci√≥n escal√≥n.
- Probar con todos los valores de entrada.
- Graficar con `matplotlib` los puntos (0,0), (0,1), (1,0), (1,1) y la l√≠nea de separaci√≥n.

---

### **Sesi√≥n 2 ‚Äì Aprendizaje autom√°tico: el gradiente descendente**

**Objetivos:**
- Comprender el concepto de error y su minimizaci√≥n.
- Introducir la idea del gradiente descendente sin f√≥rmulas complejas.
- Implementar el aprendizaje de un perceptr√≥n que aprenda autom√°ticamente una compuerta AND.

**Contenido:**
1.  Error = salida esperada ‚Äì salida real.
2.  Ajuste de pesos:  
    $w_i = w_i + \eta (y_{real} - y_{pred})x_i$
3.  Explicaci√≥n gr√°fica del gradiente descendente (usar analog√≠a de ‚Äúbajar una monta√±a‚Äù).
4.  Diferencia entre aprendizaje supervisado y no supervisado.

---

### **Sesi√≥n 3 ‚Äì Mini proyecto: Clasificador de cr√©dito simple**

**Objetivos:**
- Aplicar el perceptr√≥n a un problema real simple.
- Entender c√≥mo las variables afectan la decisi√≥n.
- Visualizar fronteras de decisi√≥n en 2D.

**Contenido:**
1.  Datos sint√©ticos: ingreso y antig√ºedad laboral ‚Üí cr√©dito aprobado (1) o no (0).
2.  Entrenamiento del perceptr√≥n.
3.  Visualizaci√≥n del plano con colores seg√∫n clasificaci√≥n.

### **Sesi√≥n 4 ‚Äì De perceptr√≥n a red neuronal**

**Objetivos:**
- Entender qu√© significa ‚Äúred multicapa‚Äù.
- Introducir funciones de activaci√≥n suaves (sigmoide, ReLU).
- Mostrar c√≥mo una red con capa oculta puede resolver XOR.

**Contenido:**
1.  Estructura general de una red MLP.
2.  Forward propagation y retropropagaci√≥n (conceptual).
3.  Mostrar ejemplo visual del XOR y c√≥mo se resuelve con dos neuronas ocultas.

---
### **Sesi√≥n 5 ‚Äì Uso de una librer√≠a simple para clasificaci√≥n**

**Objetivos:**
- Usar una librer√≠a sencilla (por ejemplo `scikit-learn`) para crear, entrenar y evaluar una red neuronal.
- Conectar los conceptos aprendidos con la pr√°ctica moderna.
    
**Contenido:**
1.  Explicaci√≥n breve de `MLPClassifier` de `scikit-learn`.
2.  Dataset cl√°sico: **Iris (clasificaci√≥n de plantas)**.
3.  Entrenamiento e inferencia con pocas l√≠neas de c√≥digo.

### **Sesi√≥n 6 ‚Äì Cierre e integraci√≥n**

**Objetivos:**
- Recapitular el flujo completo: neurona ‚Üí red ‚Üí aprendizaje ‚Üí uso.
- Conectar con aplicaciones reales (reconocimiento de voz, im√°genes, texto).
- Mostrar ejemplos r√°pidos de inferencia (por ejemplo, clasificar una flor nueva).

## 1\. ¬øQu√© problema queremos resolver?

Imaginemos algo sencillo:

> ‚ÄúTengo dos condiciones, y quiero decidir **s√≠** o **no**‚Äù.

Por ejemplo:
- ¬øDebe encenderse una alarma?
- ¬øA un usuario le doy acceso o no?
- ¬øUna puerta se abre o no?

Caso concreto para la clase:
> Dos interruptores controlan una luz.  
> La luz solo se enciende cuando **los dos** est√°n encendidos.

Eso es exactamente una compuerta l√≥gica **AND**:

| Interruptor 1 | Interruptor 2 | Luz (AND) |
| --- | --- | --- |
| 0 | 0 | 0 |
| 0 | 1 | 0 |
| 1 | 0 | 0 |
| 1 | 1 | 1 |

Hasta ac√°, nada raro.  

La pregunta es:
> ¬øPodemos hacer que una **peque√±a ‚Äúcaja matem√°tica‚Äù** tome estas decisiones sola?

Esa cajita es lo que vamos a llamar **perceptr√≥n**.

---

## 2\. La idea del perceptr√≥n

> Un perceptr√≥n es una **mini decisi√≥n autom√°tica**:
> 
> - recibe n√∫meros de entrada,
> - los combina,
> - decide si la salida es 0 o 1.

Dicho paso a paso.

### 2.1. Entradas

Tenemos dos entradas:

- $x_1$: estado del interruptor 1 (0 o 1)
- $x_2$: estado del interruptor 2 (0 o 1)

### 2.2. Pesos: qu√© tan importante es cada entrada

El perceptr√≥n no solo mira el valor, sino *cu√°nto le importa* cada valor.
- $w_1$: importancia de $x_1$
- $w_2$: importancia de $x_2$

Si un peso es m√°s grande, esa entrada ‚Äúpesa‚Äù m√°s en la decisi√≥n.  
Ejemplo intuitivo para ellos:

> Si estoy decidiendo si salir:
> - ‚Äú¬øEst√° lloviendo?‚Äù quiz√°s pesa mucho.
> - ‚Äú¬øTengo ganas?‚Äù tambi√©n.
> - ‚Äú¬øHay mosquitos?‚Äù quiz√° menos. (salvo en verano, obvio)
> 

### 2.3. El sesgo (bias): la tendencia de la decisi√≥n

Adem√°s de eso, el perceptr√≥n tiene un valor fijo, llamado $b$:
- Si $b$ es muy negativo, cuesta m√°s llegar al ‚Äú1‚Äù.
- Si $b$ es m√°s positivo, es m√°s f√°cil obtener ‚Äú1‚Äù.
    
> Es como el ‚Äúhumor‚Äù del modelo: si est√° de mal humor, casi siempre dice que no.

### 2.4. C√≥mo decide

El perceptr√≥n junta todo en una cuenta:

$$
z = w_1x_1 + w_2x_2 + b
$$

Y despu√©s hace algo muy simple:

> Si $z$ es **mayor o igual a 0**, la salida es **1**.  
> Si $z$ es **menor que 0**, la salida es **0**.

Eso es la funci√≥n de decisi√≥n:

$$
\text{salida} = \begin{cases} 1 & \text{si } z \ge 0\\ 0 & \text{si } z < 0 \end{cases}
$$

Listo. Eso es un perceptr√≥n.  
Una mini caja que:
1.  multiplica,
2.  suma,
3.  compara con 0.
    
No hay magia. Todav√≠a üòâ

---

## 3\. Us√°ndolo para hacer una compuerta AND

Ahora s√≠: queremos que el perceptr√≥n se comporte como AND.

Queremos que cumpla:
- Si (0,0) ‚Üí 0
- Si (0,1) ‚Üí 0
- Si (1,0) ‚Üí 0
- Si (1,1) ‚Üí 1
    
Eso significa:

1.  Para (0,0): queremos 0  
    $\Rightarrow w_1¬∑0 + w_2¬∑0 + b < 0$  
    $\Rightarrow b < 0$
    
2.  Para (0,1): queremos 0  
    $\Rightarrow w_1¬∑0 + w_2¬∑1 + b < 0$  
    $\Rightarrow w_2 + b < 0$
    
3.  Para (1,0): queremos 0  
    $\Rightarrow w_1¬∑1 + w_2¬∑0 + b < 0$  
    $\Rightarrow w_1 + b < 0$
    
4.  Para (1,1): queremos 1  
    $\Rightarrow w_1¬∑1 + w_2¬∑1 + b \ge 0$  
    $\Rightarrow w_1 + w_2 + b \ge 0$
    
- Sabemos que $b$ tiene que ser negativo (por el caso 0,0).
- Pero cuando ambos son 1, la suma con $b$ tiene que ser positiva.
    
Elegimos algo f√°cil:

- $w_1 = 1$
- $w_2 = 1$
- $b = -1.5$
    
Probamos:

- (0,0): $0+0-1.5 = -1.5 < 0 \Rightarrow 0$ ‚úÖ
- (0,1): $0+1-1.5 = -0.5 < 0 \Rightarrow 0$ ‚úÖ
- (1,0): $1+0-1.5 = -0.5 < 0 \Rightarrow 0$ ‚úÖ
- (1,1): $1+1-1.5 = 0.5 \ge 0 \Rightarrow 1$ ‚úÖ
    
Listo. Ya tienen su primera neurona funcionando.

> Ajustando tres numeritos (dos pesos y un sesgo) logramos que la m√°quina copie la tabla de verdad de AND.

---

## 4\. Visualizaci√≥n conceptual

- Eje X: $x_1$
- Eje Y: $x_2$
- Puntos:
    - (0,0), (0,1), (1,0) deben ir al 0.
    - (1,1) debe ir al 1.
        
La ecuaci√≥n:

$$
w_1x_1 + w_2x_2 + b = 0
$$

Es la **l√≠nea** que separa los casos con salida 0 de los casos con salida 1.

Con nuestros valores:

$$
x_1 + x_2 - 1.5 = 0
$$

Esa l√≠nea pasa entre los puntos de salida 0 y el punto (1,1) de salida 1.

> El perceptr√≥n dibuja una l√≠nea: de un lado dice ‚Äúno‚Äù, del otro lado dice ‚Äús√≠‚Äù.  
> En este ejemplo, AND se puede separar con una sola l√≠nea.  
> M√°s adelante vamos a ver casos donde una sola l√≠nea no alcanza, y ah√≠ nacen las redes.

---

## 5\. C√≥mo se ve en c√≥digo (Python puro)


```python
def perceptron(x1, x2, w1, w2, b):
    z = w1 * x1 + w2 * x2 + b
    return 1 if z >= 0 else 0

# Par√°metros para compuerta AND
w1, w2, b = 1.0, 1.0, -1.5

datos = [
    [(0, 0), 0],
    [(0, 1), 0],
    [(1, 0), 0],
    [(1, 1), 1],
]

for (x1, x2), y in datos:
    y_p = perceptron(x1, x2, w1, w2, b)
    print(f"{x1} {x2} -> {y_p} (esperado: {y})")
```

Salida esperada:

```text
0 0 -> 0
0 1 -> 0
1 0 -> 0
1 1 -> 1
```

> No hay ninguna ‚Äúl√≥gica cableada‚Äù tipo `if x1 and x2`.  
> Solo hay una f√≥rmula num√©rica.  
> Cambiando pesos y sesgo, cambiamos la regla que ‚Äúaprendi√≥‚Äù.

---

## 6\. Repasemos

1.  Un perceptr√≥n es una forma de **convertir n√∫meros de entrada en una decisi√≥n s√≠/no**.
2.  Lo hace mediante:
    - pesos (importancia),
    - un sesgo (tendencia),
    - una comparaci√≥n con 0.
3.  Podemos dise√±ar esos valores a mano para reproducir reglas simples como AND.
4.  Lo interesante viene despu√©s:
    - En lugar de elegir los pesos a mano,
    - vamos a hacer que la m√°quina **los ajuste sola** mirando ejemplos.
    - Eso es el aprendizaje, y ah√≠ entra la idea del gradiente.

Si quer√©s, en el pr√≥ximo paso te armo la **segunda clase**: mismo perceptr√≥n, pero ahora aprendiendo solo los par√°metros a partir de ejemplos (sin f√≥rmula m√°gica dada).

## Clase 2 ‚Äì C√≥mo el perceptr√≥n **aprende solo**

En la clase anterior construyeron una neurona AND ‚Äúa mano‚Äù: eligieron pesos y sesgo hasta que la cosa funcion√≥.

> En vez de ajustar los n√∫meros a mano, vamos a hacer que la m√°quina los ajuste sola mirando ejemplos.

Eso es ‚Äúaprendizaje‚Äù. Y s√≠, es tan simple como suena si lo contamos bien.

---

## 1\. Punto de partida: lo que ya tenemos

Recordatorio r√°pido (sin slides, sin trauma):
- Entradas: $x_1, x_2$
- Pesos: $w_1, w_2$
- Sesgo: $b$
- C√°lculo: $z = w_1x_1 + w_2x_2 + b$
- Regla:
    - si $z \ge 0$ ‚Üí salida = 1
    - si $z < 0$ ‚Üí salida = 0

Antes:

- Buscamos $w_1, w_2, b$ a mano para que el perceptr√≥n copie la tabla AND.
    
Ahora:
- Vamos a **partir de valores malos**
- y hacer que el propio algoritmo los vaya corrigiendo.

Esta es la intuici√≥n que queremos que se lleven.

---

## 2\. El perceptr√≥n como alumno

> No le vamos a decir al modelo ‚Äúesto es AND, hac√© esta f√≥rmula‚Äù.  
> Le vamos a pasar ejemplos correctos, y que √©l vaya ajustando sus n√∫meros hasta acertar siempre.

Ejemplos = nuestra **tabla AND**, vista como dataset:

| $x_1$ | $x_2$ | $y$ |
| - | - | - |
| 0 | 0 | 0 |
| 0 | 1 | 0 |
| 1 | 0 | 0 |
| 1 | 1 | 1 |

Esta tabla es su ‚Äúprofe‚Äù: le dice cu√°ndo est√° bien y cu√°ndo se equivoc√≥.

---

## 3\. Idea central: aprender es **corregir el error**

Para cada ejemplo hacemos tres cosas:

1. Calculamos la salida del perceptr√≥n (con los pesos actuales).
2. La comparamos con la salida correcta.
3. Si se equivoc√≥, movemos un poquito los pesos y el sesgo.
    

> Aprender = equivocarse + corregirse en la direcci√≥n adecuada.

---

## 4\. C√≥mo se corrige

Supongamos que tenemos:
- entrada: $(x_1, x_2)$
- respuesta correcta: $y$ (0 o 1)
- salida del perceptr√≥n: $\hat{y}$ (0 o 1)

Definimos el **error simple**:

$$
\text{error} = y - \hat{y}
$$

Casos:
- Si acierta ‚Üí $error = 0$ ‚Üí no tocamos nada.
- Si deber√≠a ser 1 y dijo 0 ‚Üí $error = 1$ ‚Üí hay que **subir** la salida.
- Si deber√≠a ser 0 y dijo 1 ‚Üí $error = -1$ ‚Üí hay que **bajar** la salida.

¬øC√≥mo subimos o bajamos?

Ah√≠ entra la regla de actualizaci√≥n:

$$
w_i \leftarrow w_i + \eta \cdot error \cdot x_i
$$
 
$$
b \leftarrow b + \eta \cdot error
$$

Donde $\eta$ (eta) es un numerito peque√±o llamado **tasa de aprendizaje**.


Qu√© significa cada parte:
- `error` te dice **para qu√© lado corregir**.
- `x_i` te dice **cu√°nto influy√≥ esa entrada en la decisi√≥n**.
- `Œ∑` controla **qu√© tan brusco es el cambio** (si es muy grande, se pasa de largo; si es muy chico, tarda mil a√±os).
    

- Si el modelo dijo 0 pero ten√≠a que ser 1 (error = 1):
    - sumamos algo a los pesos y al sesgo ‚Üí ser√° m√°s f√°cil que la pr√≥xima vez diga 1.
- Si dijo 1 pero deb√≠a ser 0 (error = -1):
    - restamos ‚Üí la pr√≥xima vez le va a costar m√°s decir 1.
        

No necesitan derivadas ahora. Eso lo guardamos para otro curso m√°s masoquista.

---

## 5\. El ciclo completo de aprendizaje

Describilo como receta:
1.  Elegimos pesos y sesgo al azar (aunque est√©n mal).
2.  Recorremos todos los ejemplos:
    - Para cada uno:
        - calculamos la salida,
        - vemos si se equivoc√≥,
        - actualizamos.
            
3.  Repetimos varias vueltas (epochs) hasta que:
    - ya no hay errores,
    - o nos cansemos (en la vida real es lo segundo).

Ese ‚Äúprobar ‚Üí medir ‚Üí ajustar ‚Üí repetir‚Äù es la esencia del famoso **gradiente descendente**.  
No hace falta decir el nombre si no quer√©s, pero si lo dec√≠s:

> Gradiente descendente = procedimiento para ir bajando el error paso a paso.

---

## 6\. C√≥digo en Python puro


```python
import random

# Datos de entrenamiento: (x1, x2, y_correcta)
datos = [
    ([0, 0], 0),
    ([0, 1], 0),
    ([1, 0], 0),
    ([1, 1], 1),
]

# Inicializamos pesos y sesgo con valores al azar peque√±os
w1 = random.uniform(-1, 1)
w2 = random.uniform(-1, 1)
b  = random.uniform(-1, 1)

aprendizaje = 0.1

def perceptron(x1, x2, w1, w2, b):
    z = w1 * x1 + w2 * x2 + b
    return 1 if z >= 0 else 0

for epoch in range(20):  # 20 pasadas por todos los datos
    errores = 0

    for [x1, x2], y_verdadera in datos:
        y_predicha = perceptron(x1, x2, w1, w2, b)
        error = y_verdadera - y_predicha

        # Ajuste solo si se equivoc√≥
        if error != 0:
            w1 += aprendizaje * error * x1
            w2 += aprendizaje * error * x2
            b  += aprendizaje * error
            errores += 1

    print(f"Epoch {epoch}: errores = {errores}")

    if errores == 0:
        break

print("Pesos finales:", w1, w2)
print("Sesgo final:", b)

# Probamos
for [x1, x2], y_verdadera in datos:
    print(f"{x1} {x2} -> {perceptron(x1, x2, w1, w2, b)} (esperado: {y_verdadera})")
```

- Al principio hay errores.
- Despu√©s de unas vueltas, los errores bajan a 0.
- Los pesos finales son distintos a los que pusieron a mano, pero hacen lo mismo: implementan AND.

> La computadora **descubri√≥ sola** n√∫meros que cumplen la tabla AND, solo mirando ejemplos correctos.

Eso es aprender.

---

## 7\. Visual: c√≥mo se ve ‚Äúaprender‚Äù

Si quer√©s sumar un toque visual (recomendado):
1.  Guard√° el n√∫mero de errores por epoch.
2.  Grafic√° `errores` vs `epoch` con `matplotlib`.
    

La curva deber√≠a bajar hasta llegar a 0. No hace falta m√°s para esta altura del curso. Eso les deja grabado que aprender = reducir errores.

```python
import random
import matplotlib.pyplot as plt

datos = [ # AND 
    ([0, 0], 0),
    ([0, 1], 0),
    ([1, 0], 0),
    ([1, 1], 1),
]

w1 = random.uniform(-1, 1)
w2 = random.uniform(-1, 1)
b  = random.uniform(-1, 1)

aprendizaje = 0.1

def perceptron(x1, x2, w1, w2, b):
    z = w1 * x1 + w2 * x2 + b
    return 1 if z >= 0 else 0

historia = []

for epoch in range(20):
    errores = 0
    for [x1, x2], y_verdadera in datos:
        y_predicha = perceptron(x1, x2, w1, w2, b)
        error = y_verdadera - y_predicha

        if error != 0:
            w1 += aprendizaje * error * x1
            w2 += aprendizaje * error * x2
            b  += aprendizaje * error
            errores += 1

    historia.append(errores)
    if errores == 0:
        break

plt.plot(historia, marker="o")
plt.xlabel("Epoch")
plt.ylabel("Cantidad de errores")
plt.title("C√≥mo el perceptr√≥n va aprendiendo AND")
plt.show()
```

> Cada punto es una pasada completa por los ejemplos.  
> Al principio se equivoca, despu√©s ya casi no, al final acierta todo.  
> Eso es todo lo que hace una gran parte del ‚Äúaprendizaje autom√°tico‚Äù.

---

## 8\. Resumiendo lo aprendido


1.  El perceptr√≥n ya no es solo una f√≥rmula fija: ahora **ajusta sus n√∫meros mirando ejemplos**.
2.  Usa una regla muy simple:
    - si se equivoca, corrige pesos y sesgo en el sentido correcto;
    - si acierta, no toca nada.
        
3.  El objetivo es reducir errores ‚Üí eso es la versi√≥n amigable del gradiente descendente.
4.  Esta misma idea, con m√°s neuronas y m√°s capas, escala a problemas mucho m√°s complejos.

---
# Generalizando el perceptr√≥n para cualquier cantidad de entradas

## 1\. Qu√© queremos generalizar

Antes:
- Ten√≠amos 2 entradas: $x_1, x_2$
- 2 pesos: $w_1, w_2$
- Un sesgo: $b$
    
Ahora:
- Podemos tener 3, 5, 20‚Ä¶ las que quieras:
    - Entradas: $x_1, x_2, x_3, ..., x_n$
    - Pesos: $w_1, w_2, w_3, ..., w_n$

- El c√°lculo es el mismo, solo m√°s general:

$$
z = w_1x_1 + w_2x_2 + \dots + w_nx_n + b
$$

Despu√©s:
- si $z \ge 0$ ‚Üí salida = 1
- si $z < 0$ ‚Üí salida = 0

La regla de aprendizaje tambi√©n es la misma:

$$
w_j \leftarrow w_j + \eta \cdot error \cdot x_j
$$
 
$$
b \leftarrow b + \eta \cdot error
$$

Solo que ahora $j$ recorre todas las entradas.

Nada nuevo, solo menos tedio.

---

## 2\. Encapsular todo en una clase `Perceptron`

Ahora lo envolvemos en una clase para que tus alumnos vean el patr√≥n bien limpio.

```python
import random

class Perceptron:
    def __init__(self, entradas, aprendizaje=0.1):
        # Inicializamos pesos y sesgo con valores chicos al azar
        self.pesos = [random.uniform(-1, 1) for _ in range(entradas)]
        self.sesgo = random.uniform(-1, 1)
        self.aprendizaje = aprendizaje

    def activar(self, suma): # Funci√≥n escal√≥n
        return 1 if suma >= 0 else 0

    def predecir(self, x):
        # x es una lista/tupla de entradas [x1, x2, ..., xn]
        suma = 0.0
        for xi, wi in zip(x, self.pesos):
            suma += xi * wi
        suma += self.sesgo
        return self.activar(suma)

    def entrenar(self, datos, epochs=20):
        """
        datos: lista de pares (entradas, etiqueta)
        entradas: [x1, x2, ..., xn]
        etiqueta: 0 o 1
        """

        for epoch in range(epochs):
            errores = 0

            for entradas, etiqueta_real in datos:
                prediccion = self.predecir(entradas)
                error = etiqueta_real - prediccion

                if error != 0:
                    # Ajustamos cada peso
                    self.pesos = [p + self.aprendizaje * error * e for p, e in zip(self.pesos, entradas)]
                    # Ajustamos el sesgo
                    self.sesgo += self.aprendizaje * error
                    errores += 1

            if errores == 0:
                break
```

Listo. Con esto el perceptr√≥n sirve para cualquier cantidad de variables.

---

## 3\. Ejemplo r√°pido con la compuerta AND de 2 entradas

```python
# AND con 2 entradas
datos_and_2 = [
    ([0, 0], 0),
    ([0, 1], 0),
    ([1, 0], 0),
    ([1, 1], 1),
]

p = Perceptron(entradas=2, aprendizaje=0.1)
p.entrenar(datos_and_2, epochs=20)

for x, y in datos_and_2:
    print(x, "->", p.predecir(x), "(esperado:", y, ")")
```

---

## 4\. Ejemplo con AND de 3 entradas (para que vean la gracia)

Ahora hac√©:

```python
# AND con 3 entradas: salida es 1 solo si las tres son 1
datos_and_3 = [
    ([0, 0, 0], 0),
    ([0, 0, 1], 0),
    ([0, 1, 0], 0),
    ([1, 0, 0], 0),
    ([1, 1, 0], 0),
    ([1, 0, 1], 0),
    ([0, 1, 1], 0),
    ([1, 1, 1], 1),
]

p3 = Perceptron(entradas=3, aprendizaje=0.1)
p3.entrenar(datos_and_3, epochs=30)

for x, y in datos_and_3:
    print(x, "->", p3.predecir(x), "(esperado:", y, ")")
```


> Misma clase, mismos m√©todos, distinto problema.  
> Eso es un modelo: cambi√°s los datos, no el c√≥digo interno.

---

## 5\. Resumiendo

1.  El perceptr√≥n funciona igual con 2 o con 100 entradas.
2.  Los pesos son solo una lista de numeritos que el modelo ajusta.
3.  El entrenamiento es un bucle:
    - predecir ‚Üí comparar ‚Üí corregir.
4.  El dise√±o con clase hace que usar el modelo sea natural:
    - lo creo (`Perceptron(...)`),
    - lo entreno (`entrenar`),
    - lo uso (`predecir`).
        

Vamos un paso m√°s, armamos el ejemplo del **clasificador de cr√©dito** usando exactamente esta clase, con 2 o 3 variables sencillas, para que vean un caso ‚Äúde la vida real‚Äù.


Vamos a armar la clase donde usan **el mismo perceptr√≥n gen√©rico** para decidir si aprobar o no un cr√©dito, usando datos hist√≥ricos guardados en un CSV.

Sin trucos, sin librer√≠as m√°gicas, sin mostrar c√≥mo se gener√≥ el CSV (te lo voy a ‚Äúentregar hecho‚Äù).

---

## 1\. ¬øPodemos darle un cr√©dito o no?

> ‚ÄúSomos un banco. Tenemos un hist√≥rico de personas que pidieron cr√©dito.  
> Para cada persona sabemos algunos datos simples: cu√°nto gana, hace cu√°nto trabaja, si tuvo problemas de pago antes, y si el cr√©dito fue pagado bien o fue un desastre.
> 
> Queremos que, mirando ese historial, una neurona aprenda a decir: **aprobar (1)** o **rechazar (0)**.‚Äù

Esto conecta directo con el mundo real:

- Mismas ideas que AND,
- pero con n√∫meros ‚Äúde verdad‚Äù.
    
---

## 2\. Nuestro archivo `50.3.creditos.csv`


```text
sueldo,antiguedad,cumplio
763496,72,1
722700,45,1
668067,54,1
709232,114,1
...
```

Interpretaci√≥n:
- `sueldo`: cu√°nto gana (n√∫mero grande).
- `antiguedad`: hace cu√°ntos meses trabaja en el empleo actual.
- `cumplio`: 1 si este cliente hist√≥rico cumpli√≥ con el cr√©dito (bueno), 0 si present√≥ problemas (malo).

Objetivo del perceptr√≥n:

> Aprender a predecir `cumplio` a partir de las otras columnas.

---

## 3\. Paso a paso: usar el hist√≥rico de cr√©ditos

### 3.1. Leer el CSV

Usamos solo la librer√≠a est√°ndar `csv` para cargar los datos.

```python
import csv

def cargar_datos_credito(ruta_csv):
    datos = []
    with open(ruta_csv, encoding='utf-8') as f:
        lector = csv.DictReader(f)
        for fila in lector:
            ingreso    = float(fila["sueldo"])
            antiguedad = float(fila["antiguedad"])
            cumplio    = int(fila["cumplio"])

            # Entradas (x): las 3 caracter√≠sticas
            x = [ingreso, antiguedad]
            # Etiqueta (y): 1 si buen cliente, 0 si mal cliente
            y = cumplio

            datos.append((x, y))
    return datos
```

- Cada fila del CSV es una persona.
- Tomamos algunos n√∫meros que la describen.
- Tomamos tambi√©n el resultado final (si cumpli√≥ o no).
- Eso se convierte en ejemplo para entrenar la neurona.
    

### 3.2. Un detalle pr√°ctico: escalar los valores

`sueldo` puede ser muy grande comparado con `antiguedad`.  
Si no tocamos eso, el ingreso domina todo como elefante en triciclo.

> Para que la neurona no se vuelva loca con n√∫meros muy desparejos, a veces ‚Äúacomodamos‚Äù las escalas.

Para esta clase, hac√© algo simple: dividir por un n√∫mero fijo.

```python
def normalizar_datos(datos):
    datos_norm = []
    for x, y in datos:
        ingreso    = x[0] / 1_000_000   # pasar a rango m√°s chico
        antiguedad = x[1] / 30         # suponiendo m√°x ~30 a√±os
        x_norm = [ingreso, antiguedad]
        datos_norm.append((x_norm, y))
    return datos_norm
```

No hace falta ponerlo como ‚Äúpreprocesamiento de features‚Äù. Con que entiendan ‚Äúacomodamos los n√∫meros‚Äù alcanza.

---

## 5\. Entrenar el perceptr√≥n con esos datos

Ahora juntamos todo:

```python
# 1. Cargar datos hist√≥ricos desde el CSV
datos = cargar_datos_credito("50.3.creditos.csv")

# 2. Normalizarlos un poco para que los valores est√©n en rangos razonables
datos = normalizar_datos(datos)

# 3. Crear el perceptr√≥n con 2 entradas (ingreso, antig√ºedad)
modelo = Perceptron(entradas=2, aprendizaje=0.1)

# 4. Entrenar
modelo.entrenar(datos, epochs=50)

# 5. Probar con algunos casos del propio dataset (demo simple)
aciertos = 0
for x, y_real in datos:
    y_pred = modelo.predecir(x)
    if y_pred == y_real:
        aciertos += 1

precision = aciertos / len(datos)
print(f"Precisi√≥n sobre datos hist√≥ricos: {precision:.2f}")
```

> - Creamos la neurona.
> - Le damos ejemplos del pasado.
> - Aprende a imitar las decisiones hist√≥ricas.
> - Medimos cu√°ntas acierta.
> - Ajustamos si es necesario.

Si quieren ver decisiones puntuales:

```python
ejemplo = [600000, 24]  # ingreso y antig√ºedad
# Normalizamos igual que en la funci√≥n anterior
ejemplo_norm = [
    ejemplo[0] / 1_000_000,
    ejemplo[1] / 30,
]
print("Predicci√≥n:", modelo.predecir(ejemplo_norm))  # 1 = aprobar, 0 = rechazar
```

---

## 6\. Resumiendo

1.  **Mismo mecanismo que AND**, ahora con datos de personas.
2.  La neurona:
    - toma n√∫meros que describen al cliente,
    - combina esos n√∫meros con pesos,
    - suma un sesgo,
    - compara con 0,
    - decide aprobar (1) o no (0).
3.  Los pesos y el sesgo NO los elegimos nosotros:
    - se ajustan solos mirando el hist√≥rico.
    - si se equivoca con un cliente, corrige.
    - despu√©s de muchas correcciones, se vuelve razonablemente buena.
4.  Esto es exactamente la idea de ‚Äúmodelos que aprenden a partir de datos‚Äù.

> ‚ÄúLo √∫nico que hicimos fue reemplazar reglas escritas a mano por una f√≥rmula que se ajusta sola. Eso es machine learning. Sin humo, sin ingl√©s innecesario.‚Äù


## Clase 4 ‚Äì Mejorando el clasificador de cr√©dito

Vamos directo al upgrade. Ahora:

1.  Separamos datos en **entrenamiento** y **prueba**.
2.  Dibujamos c√≥mo el perceptr√≥n separa buenos/malos en 2D.
3.  Mostramos d√≥nde se rompe (limitaci√≥n del modelo lineal).
    
Todo con el mismo perceptr√≥n casero.

```python
 # Genera datos para entrenar el perceptron. 
 # sueldo, antiguedad, aprobo_bien
 # Generar dos grupos de datos: buenos y malos clientes claramente separables

## 1\. Preparar todo (Perceptr√≥n + carga de datos)

Usamos exactamente lo que ya ten√≠as. Pod√©s presentar esto como ‚Äúc√≥digo base‚Äù de la clase:

```python
import random
import csv
import matplotlib.pyplot as plt

class Perceptron:
    def __init__(self, entradas, aprendizaje=0.1):
        self.pesos = [random.uniform(-1, 1) for _ in range(entradas)]
        self.sesgo = random.uniform(-1, 1)
        self.aprendizaje = aprendizaje

    def _activar(self, suma):
        return 1 if suma >= 0 else 0

    def predecir(self, x):
        suma = 0.0
        for xi, wi in zip(x, self.pesos):
            suma += xi * wi
        suma += self.sesgo
        return self._activar(suma)

    def entrenar(self, datos, epochs=30):
        for epoch in range(epochs):
            errores = 0
            for entradas, etiqueta_real in datos:
                prediccion = self.predecir(entradas)
                error = etiqueta_real - prediccion

                if error != 0:
                    self.pesos = [p + self.aprendizaje * error * e 
                                    for p, e in zip(self.pesos, entradas)]
                    self.sesgo += self.aprendizaje * error
                    errores += 1
            if errores == 0:
                break

def cargar_datos_credito(ruta_csv):
    datos = []
    with open(ruta_csv, newline='', encoding='utf-8') as f:
        lector = csv.DictReader(f)
        for fila in lector:
            ingreso    = float(fila["sueldo"])
            antiguedad = float(fila["antiguedad"])
            cumplio    = int(fila["cumplio"])
            x = [ingreso, antiguedad]
            y = cumplio
            datos.append((x, y))
    return datos

def normalizar_datos(datos):
    datos_norm = []
    for x, y in datos:
        ingreso    = x[0] / 1_000_000   # escala ingresos
        antiguedad = x[1] / 120         # escala antig√ºedad
        x_norm = [ingreso, antiguedad]
        datos_norm.append((x_norm, y))
    return datos_norm
```

- Hasta ac√°: leemos el hist√≥rico, armamos ejemplos, los dejamos en escalas razonables, y tenemos nuestra neurona lista.
    

## 2\. Separar entrenamiento vs prueba

> ‚ÄúNo alcanza con ver si el modelo memoriza el pasado.  
> Tenemos que ver c√≥mo responde con datos que nunca vio.‚Äù

Implementaci√≥n simple: 80% para entrenar, 20% para probar.

```python
import random

def dividir_entrenar_probar(datos, proporcion_train=0.8):
    datos_barajados = datos[:]
    random.shuffle(datos_barajados)
    corte = int(len(datos_barajados) * proporcion_train)
    train = datos_barajados[:corte]
    test  = datos_barajados[corte:]
    return train, test

# Cargar y preparar
datos = cargar_datos_credito("50.3.creditos.csv")
datos = normalizar_datos(datos)

# Separar
train, test = dividir_entrenar_probar(datos, proporcion_train=0.8)

# Crear y entrenar el modelo solo con train
modelo = Perceptron(entradas=2, aprendizaje=0.1)
modelo.entrenar(train, epochs=50)

# Evaluar en train
aciertos_entr = sum(1 for x, y in train if modelo.predecir(x) == y)
precision_entr = aciertos_entr / len(train)

# Evaluar en test
aciertos_prueba = sum(1 for x, y in test if modelo.predecir(x) == y)
prec_prueba = aciertos_prueba / len(test)

print(f"Precisi√≥n en entrenamiento: {precision_entr:.2f}")
print(f"Precisi√≥n en prueba: {prec_prueba:.2f}")
```

- Si la precisi√≥n en train es alta pero en test es baja:
    - el modelo ‚Äúaprendi√≥ de memoria‚Äù o es demasiado simple.
- Si ambas son razonables:
    - la neurona captur√≥ una regla simple del banco.
        
> ‚ÄúProbamos con casos nuevos para ver si el modelo generaliza.‚Äù

---

## 3\. Visualizar la frontera de decisi√≥n en 2D

Tenemos 2 variables, pero no queremos marearlos. Mostramos una proyecci√≥n simple:
- Usamos:
    - `sueldo` (x)
    - `antig√ºedad` (y)
    

### 3.1. Dibujar puntos y frontera de decisi√≥n

```python
def graficar_decision(modelo, datos):
    xs_buenos = []
    ys_buenos = []
    xs_malos  = []
    ys_malos  = []

    for x, y in datos:
        sueldo, antiguedad = x
        if y == 1:
            xs_buenos.append(sueldo)
            ys_buenos.append(antiguedad)
        else:
            xs_malos.append(sueldo)
            ys_malos.append(antiguedad)

    plt.scatter(xs_buenos, ys_buenos, marker='o', label='Buen pagador')
    plt.scatter(xs_malos,  ys_malos,  marker='x', label='Mal pagador')

    # Frontera de decisi√≥n del perceptr√≥n en este plano
    # pesos: [w_ingreso, w_antiguedad]
    w_ing, w_ant = modelo.pesos
    b = modelo.sesgo

    # Ecuaci√≥n: w_ing*x + w_ant*y + b = 0
    # Despejamos y:
    # y = -(w_ing / w_ant) * x - b / w_ant

    if abs(w_ant) > 1e-8:
        xs_linea = [min(xs_buenos + xs_malos, default=0),
                    max(xs_buenos + xs_malos, default=1)]
        ys_linea = []
        for xx in xs_linea:
            yy = -(w_ing / w_ant) * xx - b / w_ant
            ys_linea.append(yy)
        plt.plot(xs_linea, ys_linea, label='Frontera perceptr√≥n')

    plt.xlabel("Ingreso normalizado")
    plt.ylabel("Antig√ºedad normalizada")
    plt.title("Frontera de decisi√≥n del perceptr√≥n")
    plt.legend()
    plt.show()

# Graficar usando todo el dataset normalizado
graficar_decision(modelo, datos)
```

- Cada puntito es una persona.
- Azul: buen pagador. Rojo (o cruces): mal pagador.
- La l√≠nea es ‚Äúdonde el modelo duda‚Äù.  
    Un lado ‚Üí aprueba, otro ‚Üí rechaza.
    

Sin decir ‚Äúhiperplano‚Äù, salvo que te tiente.

---

## 4\. Mostrar las limitaciones del perceptr√≥n

Ahora la parte que abre la puerta a redes m√°s complejas.

> ‚ÄúEsta neurona solo puede separar con **una l√≠nea recta**.  
> Si los datos se mezclan de forma complicada, no alcanza.‚Äù

C√≥mo lo baj√°s:

1.  Con el gr√°fico:
    - Fijate si hay buenos y malos mezclados del mismo lado de la l√≠nea.
    - Eso muestra que, aunque entrenemos, hay cosas que una sola l√≠nea no puede separar bien.
2.  Conceptualmente:
    - Si el patr√≥n es ‚Äúsi cumple esto O esto O esto PERO no aquello‚Äù, se pone complicado.
    - Un solo perceptr√≥n es bueno para reglas m√°s o menos lineales.
    - Para patrones m√°s complejos necesitamos **m√°s neuronas**, **m√°s capas**.
        

> ‚ÄúNo es que nuestra neurona sea tonta: la obligamos a decidir con una regla demasiado simple.  
> La soluci√≥n no es m√°s fe, es m√°s capacidad: m√°s neuronas y m√°s capas. Eso es una red neuronal.‚Äù

---

# Clase 5 ‚Äì Redes Neuronales con `sklearn`

- Ven la **misma l√≥gica de siempre**, solo empacada en una herramienta real.

---

## 1\. Arranque: conectar con lo ya hecho

> ‚ÄúHasta ahora:
> - Construimos una neurona.
> - La hicimos aprender sola.
> - La usamos para decidir cr√©ditos.
>
> Hoy vamos a ver qu√© pasa cuando ponemos **varias neuronas en capas** y dejamos que una librer√≠a haga el trabajo pesado.‚Äù

Clave:
- No cambiar el discurso: es **la misma idea**, s√≥lo m√°s grande.
- Que sientan continuidad, no otro tema.

---

## 2\. El problema: clasificar flores üå∏

Present√°s el cl√°sico dataset **Iris**:

> Tenemos medidas de flores:
> - largo y ancho del s√©palo, (sepalo => hoja que protege la flor)
> - largo y ancho del p√©talo, (petalo => parte colorida de la flor)
>     y queremos clasificar la flor en 3 especies.
>
- ‚ÄúEstos 4 n√∫meros ‚Üí una etiqueta entre 3 posibles‚Äù.
    
Ejemplo visual verbal:

> Igual que antes con cr√©ditos, pero ahora:  
> entradas: 4 n√∫meros  
> salida: 0, 1 o 2 (especie A, B o C)

---

## 3\. De una neurona a una red (versi√≥n humana)

Explicaci√≥n super simple:

1.  Antes ten√≠amos:
    - una capa de entradas,
    - una √∫nica neurona que devolv√≠a 0 o 1.
2.  Ahora:
    - metemos una **capa oculta** con varias neuronas.
    - cada neurona hace lo mismo que nuestro perceptr√≥n: suma ponderada + activaci√≥n.
    - al final hay neuronas de salida que representan cada clase.
        
> ‚ÄúImaginen varios perceptrones trabajando juntos:  
> unos combinan caracter√≠sticas simples,  
> otros combinan esas combinaciones,  
> y al final alguien vota la categor√≠a.‚Äù

- M√°s neuronas + m√°s capas = puede separar patrones m√°s complejos.
- El mecanismo de aprender pesos sigue siendo:
    - probar,
    - medir error,
    - ajustar.
- Solo que ahora eso se hace con algoritmos m√°s elaborados (backprop), que no necesitamos detallar.
    
Listo. Eso es toda la teor√≠a que necesit√°s para esta clase.

---

## 4\. Usando una librer√≠a: `MLPClassifier` (Multi-Layer Perceptron Classifier)

> ‚ÄúTodo lo que hicimos a mano, ahora lo pedimos as√≠: `clf.fit(...)`.‚Äù

C√≥digo completo para mostrar en clase:

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neural_network  import MLPClassifier
from sklearn.metrics import accuracy_score

# 1. Cargar el dataset Iris
iris = load_iris()
X = iris.data        # 4 caracter√≠sticas por flor
y = iris.target      # 0, 1 o 2 seg√∫n especie

# 2. Separar en entrenamiento y prueba (como ya aprendimos, ahora con `train_test_split`)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# 3. Definir la red neuronal
# hidden_layer_sizes=(5,) -> una capa oculta con 5 neuronas
# activation='relu' -> funci√≥n de activaci√≥n moderna (no nos peleamos con ella hoy)
# max_iter=1000 -> darle tiempo a aprender

clf = MLPClassifier( hidden_layer_sizes=(5,), activation='relu', solver='adam', max_iter=1000, random_state=42 )

# 4. Entrenar la red con los datos de entrenamiento
clf.fit(X_train, y_train)

# 5. Evaluar
y_pred = clf.predict(X_test)
precision = accuracy_score(y_test, y_pred)

print("Precisi√≥n en test:", precision)

# 6. Probar con un ejemplo nuevo (tomamos uno del test solo para mostrar)
print("Ejemplo X_test[0]:", X_test[0])
print("Predicci√≥n del modelo:", clf.predict([X_test[0]])[0])
print("Etiqueta real:", y_test[0])
```

C√≥mo lo explic√°s:

- `MLPClassifier` es nuestra ‚Äúcaja de red neuronal‚Äù.
- `hidden_layer_sizes=(5,)`: le decimos ‚Äúpon√© 5 neuronas en la capa oculta‚Äù.
- `fit` = entrenar (igual que nuestro `entrenar` casero).
- `predict` = usar la red ya entrenada para inferir.
    
No necesitan m√°s detalle t√©cnico ac√°.

---

## 5\. Conectar con lo que ya saben

Esto es clave para que no vean sklearn como magia negra.

Mostr√° la analog√≠a directa:
1.  Nuestro perceptr√≥n casero:
    - Ten√≠a pesos, sesgo.
    - Ten√≠a m√©todo `entrenar`.
    - Ten√≠a m√©todo `predecir`.
        
2.  `MLPClassifier`:
    - Tiene pesos (muchos m√°s, internos).
    - Tiene `fit` (entrenar).
    - Tiene `predict` (predecir).

> ‚ÄúLa diferencia no es filos√≥fica, es de escala:  
> en vez de una neurona con 3 pesos, tenemos capas con decenas de pesos.  
> Pero el coraz√≥n es el mismo: ajustar n√∫meros para reducir error.‚Äù

---

## 6\. Un toque visual (recomendado)

Pod√©s agregar una visualizaci√≥n sencilla para no hundirlos, por ejemplo reducir a 2D (PCA) y colorear por especie.

```python
import matplotlib.pyplot as plt

# Elegir dos atributos reales para el plano 2D (0..3):
# 0: sepal length, 1: sepal width, 2: petal length, 3: petal width
idx_x, idx_y = 0, 2  # ejemplo: largo del s√©palo vs largo del p√©talo

x_axis = X[:, idx_x]
y_axis = X[:, idx_y]

# Predicciones del modelo para todos los puntos (ya entrenado)
y_pred_all = clf.predict(X)

plt.scatter(x_axis, y_axis, c=y_pred_all, cmap='viridis')
plt.title("Flores Iris coloreadas seg√∫n la red neuronal (2 atributos)")
plt.xlabel(iris.feature_names[idx_x])
plt.ylabel(iris.feature_names[idx_y])
plt.show()
```

Qu√© dec√≠s al mostrarlo:
- Cada punto es una flor.
- El color es la especie que la red neuronal predice.
- Vemos regiones donde el modelo asigna distintas clases.
- No hace falta entender el dibujo al 100%; la idea es que la red aprendi√≥ una ‚Äúfrontera‚Äù m√°s compleja que una simple l√≠nea.

---

## 7\. Resumiendo

1.  Ya sab√≠amos c√≥mo una neurona simple aprende con ejemplos.
2.  Una red neuronal es muchas neuronas como esas conectadas en capas.
3.  Hoy usamos una librer√≠a que implementa todo el mecanismo interno.
4.  Como siempre: se entrena con `fit` usando datos hist√≥ricos, se usa con `predict` sobre datos nuevos.
5.  La idea nunca cambi√≥: **ajustar par√°metros para reducir errores**.
    

Y, si quer√©s dejar picando la siguiente:

> ‚ÄúSi entendieron el perceptr√≥n casero, entender redes profundas es cuesti√≥n de escala, no de fe.‚Äù
